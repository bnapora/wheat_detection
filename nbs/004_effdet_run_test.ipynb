{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from fastai2.vision.core import _unscale_pnts\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "from effdet.anchors import Anchors,AnchorLabeler,generate_detections,MAX_DETECTION_POINTS\n",
    "from effdet.loss import DetectionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refactor after testing \n",
    "# Setting up effdet related config\n",
    "\n",
    "model_config = get_efficientdet_config('tf_efficientdet_d0')\n",
    "model = EfficientDet(model_config,pretrained_backbone=True)\n",
    "model_config.num_classes = 1\n",
    "model_config.image_size = 256\n",
    "model.class_net = HeadNet(model_config,num_outputs=model_config.num_classes,norm_kwargs=dict(eps=.001,momentum=0.01))\n",
    "path = Path('/home/heye0507/wheat_detection/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastai bbox style is [x1,y1,x2,y2], given coco-style is [x1,y1,w,h]\n",
    "def convert_fastai_bbox(box):\n",
    "    x1,y1,w,h = box\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    return [x1,y1,x2,y2]\n",
    "    \n",
    "def prep_bbox(df):\n",
    "    images, bbox = df['image_id'],df['bbox']\n",
    "    d = collections.defaultdict(list)\n",
    "    for i,b in zip(images,bbox):\n",
    "        d[i].append(convert_fastai_bbox([float(i) for i in b[1:-1].split(',')]))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path,sz=224,bs=64):\n",
    "    base = Path(path).parent\n",
    "    df = pd.read_csv(path)\n",
    "    img2bbox = prep_bbox(df)\n",
    "    dblocks = DataBlock(\n",
    "        blocks = (ImageBlock,BBoxBlock,BBoxLblBlock),\n",
    "        splitter = RandomSplitter(),\n",
    "        get_x = lambda o: str(base/'train')+'/'+o+'.jpg',\n",
    "        get_y = [lambda o: img2bbox[o], lambda o: ['wheat' for i in range(len(img2bbox[o]))]],\n",
    "        item_tfms = Resize(sz),\n",
    "        batch_tfms=[Normalize.from_stats(*imagenet_stats)],\n",
    "        n_inp=1\n",
    "    )\n",
    "    return dblocks.dataloaders(img2bbox.keys(),bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_data(path/'train.csv',sz=256,bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_pad(boxes,labels):\n",
    "    bb_keep = ((boxes[:,2] - boxes[:,0])>0).nonzero()[:,0]\n",
    "    return boxes[bb_keep],labels[bb_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup anchor with gt_bbox & gt_lbl matching\n",
    "\n",
    "anchors = Anchors(\n",
    "    model_config.min_level,model_config.max_level,\n",
    "    model_config.num_scales, model_config.aspect_ratios,\n",
    "    model_config.anchor_scale, model_config.image_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Effdet_Loss(preds, *targets):\n",
    "    class_out, box_out = preds\n",
    "    gt_bbox, gt_lbl = targets\n",
    "    batch_sz = gt_bbox.shape[0]\n",
    "    anchor_labeler = AnchorLabeler(anchors, model_config.num_classes,match_threshold=0.5)\n",
    "    loss_func = DetectionLoss(model_config)\n",
    "\n",
    "    # unpack fastai2 collated batch\n",
    "    boxes, labels = [],[]\n",
    "    perm = torch.LongTensor([1,0,3,2])\n",
    "\n",
    "    # Effdet loss function looking for list of tensors, \n",
    "    '''\n",
    "        batch_label_anchors\n",
    "            batch size\n",
    "            list of bounding box\n",
    "            list of label (float)\n",
    "    '''\n",
    "    # can this part of code using broadcasting? \n",
    "    # currently after unpad they don't have same size\n",
    "    # if unscale batchwise then un_pad, will have 128,128,128,128 needs to be removed itemwises.\n",
    "\n",
    "    for i in range(batch_sz):\n",
    "        box, lbl = un_pad(gt_bbox[i],gt_lbl[i])\n",
    "        boxes.append(_unscale_pnts(box[:,perm],256).cpu()) # to tf style, yxyx\n",
    "        labels.append(lbl.float().cpu())\n",
    "\n",
    "    # match anchors to gt_bbox and gt_lbl\n",
    "\n",
    "    cls_targets, box_targets, num_positivies = anchor_labeler.batch_label_anchors(\n",
    "        batch_sz, boxes, labels\n",
    "        )\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(len(cls_targets)):\n",
    "            cls_targets[i] = cls_targets[i].cuda()\n",
    "            box_targets[i] = box_targets[i].cuda()\n",
    "    loss, class_loss, box_loss = loss_func(class_out, box_out, cls_targets, box_targets, num_positivies)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls,model,loss_func=Effdet_Loss,model_dir='/home/heye0507/wheat_detection/model/').to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.33113112449646, lr_steep=1.0964781722577754e-06)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.200953</td>\n",
       "      <td>16.893120</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.158946</td>\n",
       "      <td>3.303419</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.263741</td>\n",
       "      <td>11.078637</td>\n",
       "      <td>02:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.988571</td>\n",
       "      <td>6.530420</td>\n",
       "      <td>02:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.938424</td>\n",
       "      <td>4.765682</td>\n",
       "      <td>02:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from kaggle https://www.kaggle.com/pestipeti/competition-metric-details-script/data\n",
    "@jit(nopython=True)\n",
    "def calculate_iou(gt, pr, form='pascal_voc') -> float:\n",
    "    \"\"\"Calculates the Intersection over Union.\n",
    "\n",
    "    Args:\n",
    "        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n",
    "        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n",
    "        form: (str) gt/pred coordinates format\n",
    "            - pascal_voc: [xmin, ymin, xmax, ymax]\n",
    "            - coco: [xmin, ymin, w, h]\n",
    "    Returns:\n",
    "        (float) Intersection over union (0.0 <= iou <= 1.0)\n",
    "    \"\"\"\n",
    "    if form == 'coco':\n",
    "        gt = gt.copy()\n",
    "        pr = pr.copy()\n",
    "\n",
    "        gt[2] = gt[0] + gt[2]\n",
    "        gt[3] = gt[1] + gt[3]\n",
    "        pr[2] = pr[0] + pr[2]\n",
    "        pr[3] = pr[1] + pr[3]\n",
    "\n",
    "    # Calculate overlap area\n",
    "    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n",
    "    \n",
    "    if dx < 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n",
    "\n",
    "    if dy < 0:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_area = dx * dy\n",
    "\n",
    "    # Calculate union area\n",
    "    union_area = (\n",
    "            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n",
    "            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n",
    "            overlap_area\n",
    "    )\n",
    "\n",
    "    return overlap_area / union_area\n",
    "\n",
    "@jit(nopython=True)\n",
    "def find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n",
    "    \"\"\"Returns the index of the 'best match' between the\n",
    "    ground-truth boxes and the prediction. The 'best match'\n",
    "    is the highest IoU. (0.0 IoUs are ignored).\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        pred: (List[Union[int, float]]) Coordinates of the predicted box\n",
    "        pred_idx: (int) Index of the current predicted box\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (int) Index of the best match GT box (-1 if no match above threshold)\n",
    "    \"\"\"\n",
    "    best_match_iou = -np.inf\n",
    "    best_match_idx = -1\n",
    "\n",
    "    for gt_idx in range(len(gts)):\n",
    "        \n",
    "        if gts[gt_idx][0] < 0:\n",
    "            # Already matched GT-box\n",
    "            continue\n",
    "        \n",
    "        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n",
    "\n",
    "        if iou < 0:\n",
    "            iou = calculate_iou(gts[gt_idx], pred, form=form)\n",
    "            \n",
    "            if ious is not None:\n",
    "                ious[gt_idx][pred_idx] = iou\n",
    "\n",
    "        if iou < threshold:\n",
    "            continue\n",
    "\n",
    "        if iou > best_match_iou:\n",
    "            best_match_iou = iou\n",
    "            best_match_idx = gt_idx\n",
    "\n",
    "    return best_match_idx\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n",
    "    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        threshold: (float) Threshold\n",
    "        form: (str) Format of the coordinates\n",
    "        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n = len(preds)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    # for pred_idx, pred in enumerate(preds_sorted):\n",
    "    for pred_idx in range(n):\n",
    "\n",
    "        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n",
    "                                            threshold=threshold, form=form, ious=ious)\n",
    "\n",
    "        if best_match_gt_idx >= 0:\n",
    "            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n",
    "            tp += 1\n",
    "            # Remove the matched GT box\n",
    "            gts[best_match_gt_idx] = -1\n",
    "\n",
    "        else:\n",
    "            # No match\n",
    "            # False positive: indicates a predicted box had no associated gt box.\n",
    "            fp += 1\n",
    "\n",
    "    # False negative: indicates a gt box had no associated predicted box.\n",
    "    fn = (gts.sum(axis=1) > 0).sum()\n",
    "\n",
    "    return tp / (tp + fp + fn)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n",
    "    \"\"\"Calculates image precision.\n",
    "\n",
    "    Args:\n",
    "        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n",
    "        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n",
    "               sorted by confidence value (descending)\n",
    "        thresholds: (float) Different thresholds\n",
    "        form: (str) Format of the coordinates\n",
    "\n",
    "    Return:\n",
    "        (float) Precision\n",
    "    \"\"\"\n",
    "    n_threshold = len(thresholds)\n",
    "    image_precision = 0.0\n",
    "    \n",
    "    ious = np.ones((len(gts), len(preds))) * -1\n",
    "    # ious = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n",
    "                                                     form=form, ious=ious)\n",
    "        image_precision += precision_at_threshold / n_threshold\n",
    "\n",
    "    return image_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3, 256, 256]), torch.Size([8, 70, 4]), torch.Size([8, 70]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "b[0].shape, b[1].shape, b[2].shape # img, bbox, bboxlbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.model(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check caution lines and FIX it after testing\n",
    "\n",
    "def my_mAP(preds,targs,img_size=256):\n",
    "    class_out, box_out = preds\n",
    "    gt_bbox, gt_lbl = targs\n",
    "    batch_size = gt_bbox.shape[0]\n",
    "    valid_img_precision = []\n",
    "    \n",
    "    \n",
    "    ## unpack fastai2 collated batch\n",
    "    boxes, labels = [],[]\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        box, lbl = un_pad(gt_bbox[i],gt_lbl[i])\n",
    "        box = _unscale_pnts(box,img_size).cpu()\n",
    "        boxes.append(box.numpy()) \n",
    "        labels.append(lbl.float().cpu())\n",
    "    ##########################################################\n",
    "        \n",
    "    ## prepare effDet format\n",
    "    '''\n",
    "        CAUTION: \n",
    "                model_config used as global var\n",
    "                anchors used as global var\n",
    "        \n",
    "        res is a list of results in the format\n",
    "        len(res) = MAX_DETECTION_POINTS, by default is 100, given dataset has max 116 bbox, suggests a higher num\n",
    "        \n",
    "        res: [[x,y,x,y,p,lbl],\n",
    "              [],\n",
    "              []...\n",
    "             ]\n",
    "        \n",
    "        each of the item in res:\n",
    "            0:4, bbox pred in xyxy pascal format\n",
    "            5, confidence\n",
    "            6, class (will always be 1. since only 1 class in the label)\n",
    "                \n",
    "        \n",
    "    ''' \n",
    "    \n",
    "    class_out,box_out,indices,classes = _post_process(model_config,class_out, box_out) # CAUTION\n",
    "    for i in range(batch_size):\n",
    "        class_out[i] = class_out[i].cpu()\n",
    "        box_out[i] = box_out[i].cpu()\n",
    "    res = _batch_detection(\n",
    "        batch_size,class_out,\n",
    "        box_out,anchors.boxes,\n",
    "        indices,classes,\n",
    "        tensor([1.]*batch_size),tensor([(img_size,img_size)]*batch_size)\n",
    "    ) # CAUTION\n",
    "    ##########################################################\n",
    "        \n",
    "    \n",
    "    '''\n",
    "        CAUTION:\n",
    "                threshold and form is hardcode\n",
    "    '''\n",
    "    for i in range(batch_size):\n",
    "        pred = res[i,:,0:4].detach().numpy() \n",
    "        valid_img_precision.append(calculate_precision(boxes[i],pred,threshold=0.5,form='pascal_voc')) # CAUTION\n",
    "    return np.mean(valid_img_precision)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet.bench import _post_process,_batch_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0016395368708878066"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mAP(preds,(b[1],b[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37764bitfastai2conda083c600ae6d54f50a73a18c04ce04a99"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
